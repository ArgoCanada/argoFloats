% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/download.R
\name{downloadIndex}
\alias{downloadIndex}
\title{Get an index of available floats}
\usage{
downloadIndex(
  server = "ftp://usgodae.org/pub/outgoing/argo",
  file = "ar_index_global_prof.txt.gz",
  destdir = ".",
  age = 7,
  quiet = FALSE,
  debug = 0
)
}
\arguments{
\item{server}{character value giving the base name of the server, used in the
construction of URL queries. Since servers tend to change over time, this
is a good argument to check, when debugging code that once worked but
now fails.}

\item{file}{character value indicating the file on the server, also
used as a pattern for the name of a constructed \code{.rda} file that
is placed in the \code{destdir} directory.
For the \verb{ftp://usgodae.org/pub/outgoing/argo} server,
two of multiple choices for \code{file} are
\code{ar_index_global_prof.txt.gz}
and
\code{argo_bio-profile_index.txt.gz}
but examination of the server will reveal other possibilities
that might be worth exploring.}

\item{destdir}{character value indicating the directory in which to store
downloaded files. The default value of \code{"."} means to store the
downloaded file in the present working directory.  Set \code{destdir=NULL}
if \code{destfile} is a filename with full path information.
File clutter is reduced by creating a top-level directory called
\code{data}, with subdirectories for various file types; see
\dQuote{Examples}.}

\item{age}{numeric value indicating how old a downloaded file
must be (in days), for it to be considered out-of-date.  The
default, \code{age=7}, limits downloads to once per week, as a way
to avoid slowing down a workflow with a download that might take
a sizeable fraction of an hour. Set \code{age=0} to force a download,
regardless of the file age.}

\item{quiet}{silence some progress indicators.  The default
is to show such indicators.}

\item{debug}{integer value indicating level of debuggin. If this
is less than 1, no debugging is done. Otherwise, some functions
will print debugging information.  If a function call fails, the
first step should be to rerun the function with \code{debug=1},
to see if the output suggests a problem in the call.}
}
\value{
A character value holding the name of the \code{.rda} file,
which is typically loaded with \code{\link[=load]{load()}}; see \dQuote{Examples}.
}
\description{
Downloads a file (or uses a cached file) and then reads it to create a
local \code{.rda} file that stores information about available float files,
as explained in \dQuote{Details}.
The download takes several of order 1 to 60 minutes, so this function
has an \code{age} argument that lets the user avoid new downloads of
data that were downloaded recently.
}
\details{
The first step is to construct a URL for downloading, based on the
\code{url} and \code{file} arguments. That URL will be a string ending in \code{.gz},
and from this the name of a local file is constructed by changing the
suffix to \code{.rda}. If that rda file is less than the age (in days)
specified by the \code{age} argument, then no downloading takes place,
and \code{\link[=downloadIndex]{downloadIndex()}} returns the name of that rda file.

However, if the local rda file is older than \code{age} days, a download
is started, using \code{\link[curl:curl_download]{curl::curl_download()}} from the \CRANpkg{curl}
package.  The data file is downloaded to a local temporary file,
and then the contents of that file are analysed, with the results
of the analysis being stored in the local rda file.

The resultant \code{.rda} file holds a list named \code{argoIndex}
that holds following elements:
\itemize{
\item \code{ftpRoot}, the FTP root  stored in the header of the source \code{file}.
\item \code{server}, the argument  provided here.
\item \code{file}, the argument provided here.
\item \code{header}, the preliminary lines in the source file that start with the \verb{#} character.
\item \code{data}, a data frame containing the items in the source file. As of
files downloaded in February 2020, this has columns named
\code{file}, \code{date}, \code{longitude}, \code{latitude}, \code{ocean}, \code{profiler_type},
\code{institution}, and \code{date_update}.
}

Note that \code{paste0(argoIndex$ftpRoot, argoIndex$data$file)} will
form a vector of names of files that can be downloaded as local
Netcdf files (ending in suffix \code{.nc}) that can be read with
\code{\link[oce:read.argo]{oce::read.argo()}} in the \CRANpkg{oce} packag, creating an
\code{argo} object.
}
\examples{
\dontrun{
# These examples assume that the ~/data/argo directory exists and is readable.
# Download whole index
ai <- downloadIndex(destdir="~/data/argo")
load(ai) # places argoIndex, a list, within the current workspace
# Plot histograms of 'date' and 'date_update'
par(mfrow=c(2, 1), mar=c(3, 3, 1, 1))
hist(argoIndex$data$date, breaks="years",
     main="", xlab="Time", freq=TRUE)
hist(argoIndex$data$date_update, breaks="years",
     main="", xlab="Last Update Time", freq=TRUE)
# Download and plot the last file in the index
url <- paste0(argoIndex$ftpRoot, "/", tail(argoIndex$data$file, 1))
file <- downloadByUrl(url, destdir="~/data/argo")
library(oce)
argo <- read.oce(file)
summary(argo)
par(mfrow=c(2, 2))
plot(argo, which="map")
mtext(argo[["time"]], cex=par("cex"))
plot(argo, which="TS")
plot(argo, which="temperature profile")
plot(argo, which="salinity profile")
}

}
\author{
Dan Kelley
}
\concept{functions related to argo data}
